# -*- coding: utf-8 -*-
"""Teacher_Student_Collemboles.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c824pIh8gAhocVvNrw8aYqlDZlVtGqGz
"""

import os
import numpy as np
import pandas as pd
from PIL import Image
import tensorflow as tf
from collections import Counter
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet import preprocess_input
import tensorflow as tf
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomContrast


os.environ["CUDA_VISIBLE_DEVICES"] = '0'

# === Chargement des donnees ===
labels_df = pd.read_csv('/home/barrage/grp3/crops/raw_crops/labels.csv')

folder_path = '/home/barrage/grp3/crops/raw_crops/'

NUM_CLASSES = 9
IMG_SIZE = 224

X_train, Y_soft, Y_hard = [], [], []

for index, row in labels_df.iterrows():
    image_name = row['img_name']
    image_path = os.path.join(folder_path, image_name)
    image = Image.open(image_path).resize((IMG_SIZE, IMG_SIZE))
    image_np = np.array(image)

    labels = [row['label1'], row['label2'], row['label3'], row['label4']]
    soft = [0] * NUM_CLASSES
    for l in labels:
        soft[int(l)] += 1
    soft = [x / 4 for x in soft]
    majority = Counter(labels).most_common(1)[0][0]

    X_train.append(image_np)
    Y_soft.append(soft)
    Y_hard.append(int(majority))

X_train = np.array(X_train)
Y_soft = np.array(Y_soft)
Y_hard = np.array(Y_hard)

# === Model creation ===
def create_model(input_shape=(224, 224, 3), num_classes=9):
    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)
    base_model.trainable = True

    model = models.Sequential([
        layers.Input(shape=input_shape),       
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model


teacher = create_model()
teacher.trainable = True  # Le teacher apprend en parallèle
student = create_model()


# Définir augmentation ici
data_augmentation = tf.keras.Sequential([
    RandomFlip("horizontal"),
    RandomRotation(0.1),
    RandomContrast(0.2),
])

def augment(x, y_soft, y_hard):
    x = tf.image.resize(x, (224, 224))
    x = tf.cast(x, tf.float32)

    # Augmentations classiques
    x = tf.image.random_flip_left_right(x)
    x = tf.image.random_contrast(x, lower=0.5, upper=1.5)
    x = tf.image.random_brightness(x, max_delta=0.3)
    x = tf.image.random_saturation(x, lower=0.5, upper=1.5)
    x = tf.image.random_hue(x, max_delta=0.05)

    # Zoom aléatoire (crop & resize)
    def random_crop(img):
        scales = list(np.arange(0.8, 1.0, 0.01))
        boxes = np.array([[1 - s, 1 - s, s, s] for s in scales])
        crops = tf.image.crop_and_resize(
            tf.expand_dims(img, 0),
            boxes=boxes,
            box_indices=np.zeros(len(boxes), dtype=int),
            crop_size=(224, 224)
        )
        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]

    x = random_crop(x)

    # Rotation aléatoire multiple de 90°
    k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)
    x = tf.image.rot90(x, k)

    # Inversion aléatoire (corrigé)
    x = tf.cond(
        tf.random.uniform([]) < 0.2,
        lambda: 255.0 - x,
        lambda: x
    )

    # Normalisation pour ResNet
    x = preprocess_input(x)
    return x, y_soft, y_hard


# Appliquer dans le dataset (et pas dans le modèle)
def preprocess(x, y_soft, y_hard):
    x = tf.image.resize(x, (224, 224))
    x = tf.cast(x, tf.float32)

    # Augmentations compatibles avec tf.data
    x = tf.image.random_flip_left_right(x)
    x = tf.image.random_contrast(x, lower=0.8, upper=1.2)
    x = tf.image.random_brightness(x, max_delta=0.1)

    x = preprocess_input(x)
    return x, y_soft, y_hard


BATCH_SIZE = 32

train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_soft, Y_hard))
train_ds = train_ds.shuffle(1024).map(augment).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)


# === Entraînement student ===
EPOCHS = 30
T = 3.0
alpha = 0.5
opt_student = tf.keras.optimizers.Adam(learning_rate=1e-4)
loss_ce = tf.keras.losses.SparseCategoricalCrossentropy()
loss_kd = tf.keras.losses.KLDivergence()
acc_student = tf.keras.metrics.SparseCategoricalAccuracy()

for epoch in range(EPOCHS):
    print(f"\n Epoch {epoch+1}/{EPOCHS}")
    total_loss_student = 0.0
    all_true_student, all_pred_student = [], []

    for step, (x_batch, y_soft_batch, y_hard_batch) in enumerate(train_ds):
        teacher_logits = teacher(x_batch, training=False)
        teacher_soft = tf.nn.softmax(teacher_logits / T)

        with tf.GradientTape() as tape_student:
            student_logits = student(x_batch, training=True)
            student_soft = tf.nn.softmax(student_logits / T)

            loss_s_ce = loss_ce(y_hard_batch, student_logits)
            loss_s_kd = loss_kd(teacher_soft, student_soft) * (T ** 2)
            loss_s = alpha * loss_s_ce + (1 - alpha) * loss_s_kd

        grads_s = tape_student.gradient(loss_s, student.trainable_variables)
        opt_student.apply_gradients(zip(grads_s, student.trainable_variables))
        total_loss_student += loss_s

        acc_student.update_state(y_hard_batch, student_logits)
        all_true_student.extend(y_hard_batch.numpy())
        all_pred_student.extend(tf.argmax(student_logits, axis=1).numpy())

    f1_student = f1_score(all_true_student, all_pred_student, average='macro')

    print(f"Student Loss: {total_loss_student/(step+1):.4f} | "
      f"Acc S: {acc_student.result().numpy():.4f} | "
      f"F1 S: {f1_student:.4f}")


# === Sauvegarde ===
teacher.save('/home/barrage/grp3/teacher_model5bis.h5')
student.save('/home/barrage/grp3/student_model5bis.h5')

test_path = '/home/barrage/grp3/datatest/'
IMG_SIZE = 224

X_test = []
name_test = []

for file_name in os.listdir(test_path):
    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(test_path, file_name)
        img = Image.open(img_path).convert('RGB')
        img = img.resize((IMG_SIZE, IMG_SIZE))
        img_array = np.array(img)
        X_test.append(img_array)
        name_test.append(file_name[:-4])


X_test = np.array(X_test, dtype=np.float32)
X_test = preprocess_input(X_test) 

predictions = student.predict(X_test, batch_size=32)

predicted_classes = np.argmax(predictions, axis=1)

df_results = pd.DataFrame({"idx" : name_test, "gt" : predicted_classes})
df_results.to_csv("submission_student5bis.csv", index=False, sep=',')